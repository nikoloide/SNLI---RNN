{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNLI + Glove.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ueYbleaF2igP",
        "L6vpbeMv2fEw",
        "-AbC2vBG2YQ5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYfc7oeX5p2k",
        "colab_type": "text"
      },
      "source": [
        "###SNLI + Glove.6B.100d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeYK6eZxfZQe",
        "colab_type": "text"
      },
      "source": [
        "Determinar si una oración de premisa está implicada, es neutral o contradice una oración de hipótesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNixt4eQ69BM",
        "colab_type": "text"
      },
      "source": [
        "* Pre-trained word vectors Glove 6B tokens, 400K vocab, 100d.\n",
        "* Pasamos los vectores de palabras sobre la capa densa con activación 'Relu'.\n",
        "* Encode the premise and hypothesis sentences using the same encoder (summation, GRU, LSTM, ...)\n",
        "* Codifique las premisas e hipótesis utilizando LSTM\n",
        "* Concatenar las oraciones resultantes\n",
        "* 3 capas densas Relu\n",
        "* softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VFHCvlFsv4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "d91e4507-90f5-42c8-b752-bf3b4c846e5d"
      },
      "source": [
        "from __future__ import print_function\n",
        "from functools import reduce\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import merge, recurrent, Dense, Input, Dropout, TimeDistributed\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "import os, re, csv, math, codecs\n",
        "from keras.layers import concatenate, Flatten, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Activation, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Bidirectional, LSTM, Reshape\n",
        "import keras.backend as K\n",
        "from keras.activations import softmax\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.activations import softmax\n",
        "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
        "np.random.seed(1337)  # for reproducibility"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XfuuV0piRh",
        "colab_type": "code",
        "outputId": "22c10b5a-80b7-4734-8bf3-2d3081bce0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%tensorflow_version 1.15"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n4Y906tp9Tt",
        "colab_type": "code",
        "outputId": "a94ed690-24b5-4a68-ca64-983ce2dc6edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYwUK0bvpj5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip \"/content/drive/My Drive/snli_1.0.zip\" > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueYbleaF2igP",
        "colab_type": "text"
      },
      "source": [
        "###Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16FPaxSVtNm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_tokens_from_binary_parse(parse):\n",
        "    return parse.replace('(', ' ').replace(')', ' ').replace('-LRB-', '(').replace('-RRB-', ')').split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQoyGjZRr_Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(fn, limit=None):\n",
        "  raw_data = list(yield_examples(fn=fn, limit=limit))\n",
        "  left = [s1 for _, s1, s2 in raw_data]\n",
        "  right = [s2 for _, s1, s2 in raw_data]\n",
        "  print(max(len(x.split()) for x in left))\n",
        "  print(max(len(x.split()) for x in right))\n",
        "\n",
        "  LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
        "  Y = np.array([LABELS[l] for l, s1, s2 in raw_data])\n",
        "  Y = np_utils.to_categorical(Y, len(LABELS))\n",
        "\n",
        "  return left, right, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFEm8G6sFsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yield_examples(fn, skip_no_majority=True, limit=None):\n",
        "  for i, line in enumerate(open(fn)):\n",
        "    if limit and i > limit:\n",
        "      break\n",
        "    data = json.loads(line)\n",
        "    label = data['gold_label']\n",
        "    s1 = ' '.join(extract_tokens_from_binary_parse(data['sentence1_binary_parse']))\n",
        "    s2 = ' '.join(extract_tokens_from_binary_parse(data['sentence2_binary_parse']))\n",
        "    if skip_no_majority and label == '-':\n",
        "      continue\n",
        "    yield (label, s1, s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6vpbeMv2fEw",
        "colab_type": "text"
      },
      "source": [
        "###Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexTATlRzwvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_seq = lambda X: pad_sequences(tokenizer.texts_to_sequences(X), maxlen=MAX_LEN)\n",
        "prepare_data = lambda data: (to_seq(data[0]), to_seq(data[1]), data[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbC2vBG2YQ5",
        "colab_type": "text"
      },
      "source": [
        "###Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbBlJw8poqRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c271b2c1-0b92-4fe8-f150-563123be27e0"
      },
      "source": [
        "training = get_data('snli_1.0/snli_1.0_train.jsonl')\n",
        "validation = get_data('snli_1.0/snli_1.0_dev.jsonl')\n",
        "test = get_data('snli_1.0/snli_1.0_test.jsonl')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82\n",
            "62\n",
            "59\n",
            "55\n",
            "57\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ejlDDJ02QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=\"UNK\")\n",
        "tokenizer = Tokenizer(lower=False, filters='')\n",
        "tokenizer.fit_on_texts(training[0] + training[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMo1429htlCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowest index from the tokenizer is 1 - we need to include 0 in our vocab count\n",
        "VOCAB = len(tokenizer.word_counts) + 1\n",
        "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejf5BGlq2Kdb",
        "colab_type": "text"
      },
      "source": [
        "### Veamos algunos ejemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuKCgYCeAN-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "816f6e06-0875-4a02-c1c0-3f5135c4909e"
      },
      "source": [
        "training[0][0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A person on a horse jumps over a broken down airplane .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9b0YsrqAQVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00811fd1-2416-461e-98fe-d5113ba2a46d"
      },
      "source": [
        "training[1][0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A person is training his horse for a competition .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_YTxPxaARhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eafc9882-2384-457d-f4fe-33060f4f2212"
      },
      "source": [
        "training[2][0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqp-9_JP2tzo",
        "colab_type": "text"
      },
      "source": [
        "###Prepare dataset - Training, Validation, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ASXBrM1saW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 42\n",
        "training = prepare_data(training)\n",
        "validation = prepare_data(validation)\n",
        "test = prepare_data(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UppdZ75Fqhnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #Ejemplo de prepare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jdhtp9auFE",
        "colab_type": "code",
        "outputId": "4b54b747-d096-4958-bc8d-07a05432010d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "training[0][0]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    3,   45,    8,\n",
              "          2,  193,  205,   81,    2, 1171,   40,  822,    1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zur6tZlibL-U",
        "colab_type": "code",
        "outputId": "102916e8-0bae-464b-d7d3-bfb9b0be8508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "training[1][0]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "         45,    5, 1175,   21,  193,   38,    2,  456,    1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDZvVjQacRhi",
        "colab_type": "code",
        "outputId": "d93faec2-9069-4e38-8d00-c9c24370947e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training[2][0]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmhK5zTXtvZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_seq = lambda X: pad_sequences(tokenizer.texts_to_sequences(X), maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0I-kv7YY639",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepare_data = lambda data: (to_seq(data[0]), to_seq(data[1]), data[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUh955FY1-SN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fc681a2-33fc-4cae-9150-b43c8c5e776b"
      },
      "source": [
        "print('Build model...')\n",
        "print('Vocab size =', VOCAB)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Vocab size = 42391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPpeigT13_G9",
        "colab_type": "text"
      },
      "source": [
        "###Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1893ac92-9090-4784-d088-cfda43838c2e",
        "id": "t3Mq88R85BkJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#load embeddings\n",
        "EMBEDDING_DIR = \"/content/drive/My Drive/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(EMBEDDING_DIR+'glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94sx69Bz3eLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBED_HIDDEN_SIZE = 300\n",
        "# Embedding layer\n",
        "embed = Embedding(VOCAB, EMBED_HIDDEN_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False)\n",
        "# A dense layer applied over each sequence point\n",
        "translate = TimeDistributed(Dense(SENT_HIDDEN_SIZE, activation='relu'))\n",
        "# A layer to sum up the sequence of words\n",
        "SumEmbeddings = keras.layers.core.Lambda(lambda x: K.sum(x, axis=1), output_shape=(SENT_HIDDEN_SIZE, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZiR1VQE4Fa0",
        "colab_type": "text"
      },
      "source": [
        "###Prepare embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ljv5P4Ada1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "embed_dim=100\n",
        "embedding_matrix=np.zeros([VOCAB+4,embed_dim])\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "  if idx <= VOCAB and word in embeddings_index:\n",
        "    embedding_matrix[idx+3,:]=embeddings_index[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cij1Ue_B6Jbk",
        "colab_type": "text"
      },
      "source": [
        "###Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwV0Ud4M2xkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "12f0b40f-112a-4636-89b8-c15393f0b249"
      },
      "source": [
        "SENT_HIDDEN_SIZE = 300\n",
        "translate = TimeDistributed(Dense(SENT_HIDDEN_SIZE, activation='relu'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbLm17A04KXh",
        "colab_type": "text"
      },
      "source": [
        "###Premisas e Hipotesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivGCviwY29Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB=VOCAB+4\n",
        "premise = Input(shape=(MAX_LEN,), dtype='int32')\n",
        "hypothesis = Input(shape=(MAX_LEN,), dtype='int32')\n",
        "\n",
        "prem = embed(premise)\n",
        "hypo = embed(hypothesis)\n",
        "\n",
        "prem = translate(prem)\n",
        "hypo = translate(hypo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp2sTKJQhjkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_dim=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5eULAHJ5s79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39ff7a07-3124-4392-cdc8-e76668f4c749"
      },
      "source": [
        "training[0].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(549367, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o_7zu-a4SNI",
        "colab_type": "text"
      },
      "source": [
        "###Inputs and concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m43hyvp6l7v2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9be56b7d-72dd-4cff-96aa-ce525f3f9fae"
      },
      "source": [
        "DP = 0.1\n",
        "RNN = recurrent.LSTM\n",
        "# RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))\n",
        "rnn = RNN(return_sequences=True, **rnn_kwargs)\n",
        "rnn_kwargs = dict(output_dim=SENT_HIDDEN_SIZE, dropout_W=DP, dropout_U=DP)\n",
        "VOCAB=VOCAB+4\n",
        "# 2 pairs of input sentences\n",
        "premise = Input(shape=(MAX_LEN, ), dtype='int32')\n",
        "hypothesis = Input(shape=(MAX_LEN, ), dtype='int32')\n",
        "# Get the word embeddings for each of these 2 pairs\n",
        "prem = embed(premise)  # [batchsize, Psize, Embedsize]\n",
        "hypo = embed(hypothesis) # [batchsize, Hsize, Embedsize]\n",
        "# Apply the Dense layer\n",
        "prem = translate(prem)\n",
        "hypo = translate(hypo)\n",
        "# Sum up the sequence\n",
        "prem = rnn(prem)\n",
        "hypo = rnn(hypo)\n",
        "prem = BatchNormalization()(prem)\n",
        "hypo = BatchNormalization()(hypo)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyz6iDfwmoqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0b73c120-f9f6-459e-f927-143e4bb2ee1b"
      },
      "source": [
        "# Combined the 2 sentences\n",
        "joint = concatenate([prem, hypo])\n",
        "joint = Dropout(dropout)(joint)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0WzGNFH4iWZ",
        "colab_type": "text"
      },
      "source": [
        "###Capas Densas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRm4STU5nBEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L2 = 4e-6\n",
        "for i in range(3):\n",
        "        joint = Dense(2 * SENT_HIDDEN_SIZE, activation='relu', kernel_regularizer=l2(L2) if L2 else None)(joint)\n",
        "        joint = Dropout(dropout)(joint)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8QVF1eH6phX",
        "colab_type": "text"
      },
      "source": [
        "###Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_hJaB0nnBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = Dense(len(LABELS), activation='softmax')(joint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylnVWg6d6u54",
        "colab_type": "text"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDURJtsd6vet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[premise, hypothesis], outputs=pred)\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKF4eAfnz7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "ab90cc99-4028-4950-a327-981d57e927e2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 42)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 42)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 42, 300)      12717300    input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 42, 300)      90300       embedding_1[2][0]                \n",
            "                                                                 embedding_1[3][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 300)          0           time_distributed_2[2][0]         \n",
            "                                                                 time_distributed_2[3][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 300)          1200        lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 300)          1200        lambda_1[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 600)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 600)          360600      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 600)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 600)          360600      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 600)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 600)          360600      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 600)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 3)            1803        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 13,893,603\n",
            "Trainable params: 1,175,103\n",
            "Non-trainable params: 12,718,500\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa1mhWhWn4hq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "7a3a1b45-4f2e-4352-b14c-272f71b3d97d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
        "_, tmpfn = tempfile.mkstemp()\n",
        "BATCH_SIZE = 512\n",
        "MAX_EPOCHS = 5\n",
        "# Save the best model during validation and bail out of training early if we're not improving\n",
        "callbacks = [#EarlyStopping(patience=PATIENCE),\n",
        "        ModelCheckpoint(tmpfn, save_best_only=True, save_weights_only=True),\n",
        "        History(),\n",
        "    ]\n",
        "model.fit(\n",
        "        [training[0], training[1]],\n",
        "        training[2],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=MAX_EPOCHS,\n",
        "        validation_data=([validation[0], validation[1]], validation[2]),\n",
        "        callbacks=callbacks)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 549367 samples, validate on 9842 samples\n",
            "Epoch 1/5\n",
            "549367/549367 [==============================] - 491s 893us/step - loss: 0.6908 - acc: 0.7115 - val_loss: 0.9477 - val_acc: 0.5017\n",
            "Epoch 2/5\n",
            "549367/549367 [==============================] - 487s 886us/step - loss: 0.6593 - acc: 0.7286 - val_loss: 0.6234 - val_acc: 0.7495\n",
            "Epoch 3/5\n",
            "549367/549367 [==============================] - 492s 895us/step - loss: 0.6381 - acc: 0.7401 - val_loss: 0.6387 - val_acc: 0.7402\n",
            "Epoch 4/5\n",
            "549367/549367 [==============================] - 491s 894us/step - loss: 0.6214 - acc: 0.7490 - val_loss: 0.6003 - val_acc: 0.7633\n",
            "Epoch 5/5\n",
            "549367/549367 [==============================] - 499s 909us/step - loss: 0.6082 - acc: 0.7564 - val_loss: 0.5792 - val_acc: 0.7758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18c1f0ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B6NG-Mx5XHs",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttUB5QMP5T_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe612e25-ceab-4c3a-b949-6ff7e5a4c590"
      },
      "source": [
        "# Restore the best found model during validation\n",
        "model.load_weights(tmpfn)\n",
        "\n",
        "loss, acc = model.evaluate([test[0], test[1]], test[2], batch_size=BATCH_SIZE)\n",
        "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9824/9824 [==============================] - 4s 372us/step\n",
            "Test loss / test accuracy = 0.5847 / 0.7731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QLmIxG_GMJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}